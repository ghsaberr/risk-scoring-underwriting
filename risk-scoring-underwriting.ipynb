{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bba22f-d282-49c4-a0d3-7e6ad50979da",
   "metadata": {},
   "source": [
    "# Risk Scoring & Underwriting\n",
    "Risk Scoring and Underwriting are critical components in the financial and insurance industries, particularly in the evaluation and management of risk associated with lending, insurance policies, or other financial products.\n",
    "## 1. Data Integration & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfe2a22-d0d9-4a3d-b94a-d0192cbcb366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6077b539-7576-4280-ade8-93b9727b036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class\n",
    "class ARDPreprocessor:\n",
    "    \"\"\"\n",
    "    Automated Risk Data (ARD) Preprocessing Module\n",
    "    Handles missing values, encodes categorical variables, and scales numerical features.\n",
    "    \"\"\"\n",
    "    # Constructor method to initialize the class\n",
    "    def __init__(self, num_strategy='median', cat_strategy='most_frequent', scaler=StandardScaler(), encoder=OneHotEncoder(handle_unknown='ignore')):\n",
    "        self.num_imputer = SimpleImputer(strategy=num_strategy)\n",
    "        self.cat_imputer = SimpleImputer(strategy=cat_strategy)\n",
    "        self.scaler = scaler\n",
    "        self.encoder = encoder\n",
    "        self.preprocessor = None\n",
    "\n",
    "        # Configure logging to display messages at the INFO level and above\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # Define a fit method to fit the preprocessing pipeline to the input data\n",
    "    def fit(self, df, numeric_features, categorical_features):\n",
    "        # Begin a try block to handle potential errors during fitting\n",
    "        try:\n",
    "            # Create a Pipeline for numeric features\n",
    "            numeric_pipeline = Pipeline([\n",
    "                ('imputer', self.num_imputer),\n",
    "                ('scaler', self.scaler)\n",
    "            ])\n",
    "            # Create a Pipeline for categorical features\n",
    "            categorical_pipeline = Pipeline([\n",
    "                ('imputer', self.cat_imputer),\n",
    "                ('encoder', self.encoder)\n",
    "            ])\n",
    "            # Combine the numeric and categorical pipelines into a single preprocessing object\n",
    "            self.preprocessor = ColumnTransformer([\n",
    "                ('num', numeric_pipeline, numeric_features),\n",
    "                ('cat', categorical_pipeline, categorical_features)\n",
    "            ])\n",
    "            # Fit the ColumnTransformer to the input DataFrame df\n",
    "            self.preprocessor.fit(df)\n",
    "            logging.info(\"Preprocessor fitted successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during fitting: {e}\")\n",
    "            raise\n",
    "\n",
    "    # Apply the fitted preprocessing pipeline to transform the input data\n",
    "    def transform(self, df):\n",
    "        try:\n",
    "            transformed_data = self.preprocessor.transform(df)\n",
    "            feature_names = self.preprocessor.get_feature_names_out()\n",
    "            return pd.DataFrame(transformed_data, columns=feature_names)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during transformation: {e}\")\n",
    "            raise\n",
    "\n",
    "    # Combine fitting and transformation into a single method\n",
    "    def fit_transform(self, df, numeric_features, categorical_features):\n",
    "        self.fit(df, numeric_features, categorical_features)\n",
    "        return self.transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a7c24-4b73-4ef2-b98c-2290c007e3e4",
   "metadata": {},
   "source": [
    "The `ARDPreprocessor` class is a modular and reusable preprocessing module.\n",
    "\n",
    "- It handles missing values, scales numeric features, and encodes categorical features.\n",
    "\n",
    "- It uses `Pipeline` and `ColumnTransformer` for a clean and consistent workflow.\n",
    "\n",
    "- It includes error handling and logging for robustness.\n",
    "\n",
    "- The `fit_transform` method provides a convenient way to fit and transform data in one step.\n",
    "\n",
    "Here's a breakdown of the steps:\n",
    "\n",
    "1. Fitting:\n",
    "\n",
    "- The `SimpleImputer` learns the mean (or other specified statistic) of the numeric features.\n",
    "\n",
    "- The `StandardScaler` computes the mean and standard deviation of the numeric features.\n",
    "\n",
    "2. Transformation:\n",
    "\n",
    "- The `SimpleImputer` replaces missing values with the learned mean.\n",
    "\n",
    "- The `StandardScaler` standardizes the features using the computed mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e1d40-9e38-4885-9389-76746f44ad1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

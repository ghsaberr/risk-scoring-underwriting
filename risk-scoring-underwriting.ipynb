{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bba22f-d282-49c4-a0d3-7e6ad50979da",
   "metadata": {},
   "source": [
    "# Risk Scoring & Underwriting\n",
    "Risk Scoring and Underwriting are critical components in the financial and insurance industries, particularly in the evaluation and management of risk associated with lending, insurance policies, or other financial products.\n",
    "## 1. Data Integration & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfe2a22-d0d9-4a3d-b94a-d0192cbcb366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6077b539-7576-4280-ade8-93b9727b036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class\n",
    "class ARDPreprocessor:\n",
    "    \"\"\"\n",
    "    Automated Risk Data (ARD) Preprocessing Module\n",
    "    Handles missing values, encodes categorical variables, and scales numerical features.\n",
    "    \"\"\"\n",
    "    # Constructor method to initialize the class\n",
    "    def __init__(self, num_strategy='median', cat_strategy='most_frequent', scaler=StandardScaler(), encoder=OneHotEncoder(handle_unknown='ignore')):\n",
    "        self.num_imputer = SimpleImputer(strategy=num_strategy)\n",
    "        self.cat_imputer = SimpleImputer(strategy=cat_strategy)\n",
    "        self.scaler = scaler\n",
    "        self.encoder = encoder\n",
    "        self.preprocessor = None\n",
    "\n",
    "        # Configure logging to display messages at the INFO level and above\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # Define a fit method to fit the preprocessing pipeline to the input data\n",
    "    def fit(self, df, numeric_features, categorical_features):\n",
    "        # Begin a try block to handle potential errors during fitting\n",
    "        try:\n",
    "            # Create a Pipeline for numeric features\n",
    "            numeric_pipeline = Pipeline([\n",
    "                ('imputer', self.num_imputer),\n",
    "                ('scaler', self.scaler)\n",
    "            ])\n",
    "            # Create a Pipeline for categorical features\n",
    "            categorical_pipeline = Pipeline([\n",
    "                ('imputer', self.cat_imputer),\n",
    "                ('encoder', self.encoder)\n",
    "            ])\n",
    "            # Combine the numeric and categorical pipelines into a single preprocessing object\n",
    "            self.preprocessor = ColumnTransformer([\n",
    "                ('num', numeric_pipeline, numeric_features),\n",
    "                ('cat', categorical_pipeline, categorical_features)\n",
    "            ])\n",
    "            # Fit the ColumnTransformer to the input DataFrame df\n",
    "            self.preprocessor.fit(df)\n",
    "            logging.info(\"Preprocessor fitted successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during fitting: {e}\")\n",
    "            raise\n",
    "\n",
    "    # Apply the fitted preprocessing pipeline to transform the input data\n",
    "    def transform(self, df):\n",
    "        try:\n",
    "            transformed_data = self.preprocessor.transform(df)\n",
    "            feature_names = self.preprocessor.get_feature_names_out()\n",
    "            return pd.DataFrame(transformed_data, columns=feature_names)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during transformation: {e}\")\n",
    "            raise\n",
    "\n",
    "    # Combine fitting and transformation into a single method\n",
    "    def fit_transform(self, df, numeric_features, categorical_features):\n",
    "        self.fit(df, numeric_features, categorical_features)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a7c24-4b73-4ef2-b98c-2290c007e3e4",
   "metadata": {},
   "source": [
    "The `ARDPreprocessor` class is a modular and reusable preprocessing module.\n",
    "\n",
    "- It handles missing values, scales numeric features, and encodes categorical features.\n",
    "\n",
    "- It uses `Pipeline` and `ColumnTransformer` for a clean and consistent workflow.\n",
    "\n",
    "- It includes error handling and logging for robustness.\n",
    "\n",
    "- The `fit_transform` method provides a convenient way to fit and transform data in one step.\n",
    "\n",
    "Here's a breakdown of the steps:\n",
    "\n",
    "1. Fitting:\n",
    "\n",
    "- The `SimpleImputer` learns the mean (or other specified statistic) of the numeric features.\n",
    "\n",
    "- The `StandardScaler` computes the mean and standard deviation of the numeric features.\n",
    "\n",
    "2. Transformation:\n",
    "\n",
    "- The `SimpleImputer` replaces missing values with the learned mean.\n",
    "\n",
    "- The `StandardScaler` standardizes the features using the computed mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169e1d40-9e38-4885-9389-76746f44ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine multiple datasets\n",
    "file_paths = ['application_record.csv', 'credit_record.csv']\n",
    "dfs = [pd.read_csv(file) for file in file_paths]\n",
    "\n",
    "# Concatenate DataFrames into a single DataFrame\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f39a1-dd51-467b-b510-bf826293d6e4",
   "metadata": {},
   "source": [
    "This code snippet loads and combines multiple datasets from the specified file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ffc69c-ffe0-4ab0-af5e-b7236996b58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape (rows, columns):\n",
      " (1487132, 20)\n",
      "Dataset Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1487132 entries, 0 to 1487131\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   ID                   1487132 non-null  int64  \n",
      " 1   CODE_GENDER          438557 non-null   object \n",
      " 2   FLAG_OWN_CAR         438557 non-null   object \n",
      " 3   FLAG_OWN_REALTY      438557 non-null   object \n",
      " 4   CNT_CHILDREN         438557 non-null   float64\n",
      " 5   AMT_INCOME_TOTAL     438557 non-null   float64\n",
      " 6   NAME_INCOME_TYPE     438557 non-null   object \n",
      " 7   NAME_EDUCATION_TYPE  438557 non-null   object \n",
      " 8   NAME_FAMILY_STATUS   438557 non-null   object \n",
      " 9   NAME_HOUSING_TYPE    438557 non-null   object \n",
      " 10  DAYS_BIRTH           438557 non-null   float64\n",
      " 11  DAYS_EMPLOYED        438557 non-null   float64\n",
      " 12  FLAG_MOBIL           438557 non-null   float64\n",
      " 13  FLAG_WORK_PHONE      438557 non-null   float64\n",
      " 14  FLAG_PHONE           438557 non-null   float64\n",
      " 15  FLAG_EMAIL           438557 non-null   float64\n",
      " 16  OCCUPATION_TYPE      304354 non-null   object \n",
      " 17  CNT_FAM_MEMBERS      438557 non-null   float64\n",
      " 18  MONTHS_BALANCE       1048575 non-null  float64\n",
      " 19  STATUS               1048575 non-null  object \n",
      "dtypes: float64(10), int64(1), object(9)\n",
      "memory usage: 226.9+ MB\n",
      "\n",
      "First 5 rows:\n",
      "         ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "0  5008804           M            Y               Y           0.0   \n",
      "1  5008805           M            Y               Y           0.0   \n",
      "2  5008806           M            Y               Y           0.0   \n",
      "3  5008808           F            N               Y           0.0   \n",
      "4  5008809           F            N               Y           0.0   \n",
      "\n",
      "   AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "0          427500.0               Working               Higher education   \n",
      "1          427500.0               Working               Higher education   \n",
      "2          112500.0               Working  Secondary / secondary special   \n",
      "3          270000.0  Commercial associate  Secondary / secondary special   \n",
      "4          270000.0  Commercial associate  Secondary / secondary special   \n",
      "\n",
      "     NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
      "0        Civil marriage   Rented apartment    -12005.0        -4542.0   \n",
      "1        Civil marriage   Rented apartment    -12005.0        -4542.0   \n",
      "2               Married  House / apartment    -21474.0        -1134.0   \n",
      "3  Single / not married  House / apartment    -19110.0        -3051.0   \n",
      "4  Single / not married  House / apartment    -19110.0        -3051.0   \n",
      "\n",
      "   FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
      "0         1.0              1.0         0.0         0.0             NaN   \n",
      "1         1.0              1.0         0.0         0.0             NaN   \n",
      "2         1.0              0.0         0.0         0.0  Security staff   \n",
      "3         1.0              0.0         1.0         1.0     Sales staff   \n",
      "4         1.0              0.0         1.0         1.0     Sales staff   \n",
      "\n",
      "   CNT_FAM_MEMBERS  MONTHS_BALANCE STATUS  \n",
      "0              2.0             NaN    NaN  \n",
      "1              2.0             NaN    NaN  \n",
      "2              2.0             NaN    NaN  \n",
      "3              1.0             NaN    NaN  \n",
      "4              1.0             NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the dataset (rows, columns)\n",
    "print(\"Dataset shape (rows, columns):\\n\", df.shape)\n",
    "\n",
    "# Get dataset information (column names, non-null counts, data types)\n",
    "print(\"Dataset Info:\\n\")\n",
    "df.info()\n",
    "\n",
    "# Display first 5 rows\n",
    "print(\"\\nFirst 5 rows:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b6692-c1d6-415f-85de-679563dbcab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
